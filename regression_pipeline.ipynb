{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "gather": {
          "logged": 1660593088749
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Dataset, Workspace, Experiment, Datastore\n",
        "from azureml.core import Environment, Model\n",
        "from azureml.core.runconfig import RunConfiguration\n",
        "from azureml.data.datapath import DataPath\n",
        "from azureml.data import OutputFileDatasetConfig\n",
        "from azureml.pipeline.steps import PythonScriptStep\n",
        "from azureml.pipeline.core import Pipeline\n",
        "from azureml.pipeline.core.run import PipelineRun\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1660590734860
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Setup a workspace\n",
        "ws = Workspace.from_config('config.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1660590735333
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bike_pipeline\n"
          ]
        }
      ],
      "source": [
        "# Create a folder for the pipeline step files\n",
        "experiment_folder = 'bike_pipeline'\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "print(experiment_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting bike_pipeline/prep_bike.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile $experiment_folder/prep_bike.py\n",
        "# Import libraries\n",
        "import os \n",
        "import argparse \n",
        "import pandas as pd \n",
        "import pickle\n",
        "from azureml.core import Run, Workspace\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Get parameters\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--input-data\", type=str, dest='raw_dataset_id', help='raw dataset')\n",
        "parser.add_argument('--prepped-data', type=str, dest='prepped_data', default='prepped_data', help='Folder for results')\n",
        "args = parser.parse_args()\n",
        "save_folder = args.prepped_data\n",
        "\n",
        "# Get the experiment run context \n",
        "run = Run.get_context()\n",
        " \n",
        "# load the data (passed as an input dataset)\n",
        "print('Loading dataset...')\n",
        "bike_data = run.input_datasets['raw_data'].to_pandas_dataframe()\n",
        "\n",
        "# Log raw row count()\n",
        "row_count = (len(bike_data))\n",
        "run.log('raw_rows', row_count)\n",
        "\n",
        "# remove all nulls\n",
        "bike_data = bike_data.dropna()\n",
        "\n",
        "# Normalize numeric collumns\n",
        "scaler = MinMaxScaler()\n",
        "num_cols = ['temp' ,'atemp' ,'humidity' ,'windspeed' ,'weather' ,'holiday' , 'workingday', 'season']\n",
        "bike_data[num_cols] = scaler.fit_transform(bike_data[num_cols])\n",
        "\n",
        "# Log processed rows\n",
        "row_count = (len(bike_data))\n",
        "run.log('processed_rows', row_count)\n",
        "\n",
        "# Save the prepped data\n",
        "print(\"Saving Data...\")\n",
        "os.makedirs(save_folder, exist_ok=True)\n",
        "save_path = os.path.join(save_folder,'bike_data.csv')\n",
        "bike_data.to_csv(save_path, index=False, header=True)\n",
        "\n",
        "# End the run\n",
        "run.complete()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting bike_pipeline/train_bike.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile $experiment_folder/train_bike.py\n",
        "# Import libraries\n",
        "from azureml.core import Run, Model\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "\n",
        "from hyperopt import tpe, STATUS_OK, Trials, hp, fmin, STATUS_OK, space_eval\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "# Get parameters\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--training-data\", type=str, dest='training_data', help='training data')\n",
        "args = parser.parse_args()\n",
        "training_data = args.training_data\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# load the prepared data file in the training folder\n",
        "print(\"Loading Data...\")\n",
        "file_path = os.path.join(training_data, 'bike_data.csv')\n",
        "bike_data = pd.read_csv(file_path)\n",
        "\n",
        "# Separate features and labels\n",
        "X, y = bike_data[['temp' ,'atemp' ,'humidity' ,'windspeed' ,'weather' ,'holiday' , 'workingday', 'season']].values, bike_data['count'].values\n",
        "\n",
        "# Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "space = {\n",
        "    'learning_rate':    hp.choice('learning_rate',    np.arange(0.05, 1.00, 0.05)),\n",
        "    'max_depth':        hp.choice('max_depth',        np.arange(5, 16, 1, dtype=int)),\n",
        "    'min_child_weight': hp.choice('min_child_weight', np.arange(1, 8, 1, dtype=int)),\n",
        "    'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.3, 0.8, 0.1)),\n",
        "    'subsample':        hp.choice('subsample',        [0, 0.50, 0.8, 1]),\n",
        "    'n_estimators':     hp.choice('n_estimators',     range(10, 500, 10)),\n",
        "    'tree_method':      hp.choice('tree_method',      ['hist'])\n",
        "}\n",
        "\n",
        "# Objective function\n",
        "def objective(params):\n",
        "    # Instantiate model\n",
        "    model = xgb.XGBRegressor(**params)\n",
        "\n",
        "    # Fit and predict\n",
        "    model.fit(X_train, y_train)\n",
        "    y_hat = model.predict(X_test)\n",
        "    y_hat = y_hat.clip(min=0)\n",
        "    \n",
        "    # Calculate the root mean squared error\n",
        "    rmsle = np.sqrt(mean_squared_log_error(y_test, y_hat))\n",
        "\n",
        "    # Retrun loss, status and model\n",
        "    return {'loss': rmsle, 'status': STATUS_OK, 'model': model}\n",
        "\n",
        "# Trials to track progress\n",
        "bayes_trials = Trials()\n",
        "\n",
        "# Optimize\n",
        "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=200, trials=bayes_trials)\n",
        "params = space_eval(space, best)\n",
        "\n",
        "# Train light gradient boosting model\n",
        "print('Training a decision tree model...')\n",
        "model = xgb.XGBRegressor(**params).fit(X_train, y_train)\n",
        "\n",
        "# calculate accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "y_hat = y_hat.clip(min=0)\n",
        "msle = mean_squared_log_error(y_test, y_hat)\n",
        "print(msle)\n",
        "\n",
        "# Save the trained model in the outputs folder\n",
        "print(\"Saving model...\")\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "model_file = os.path.join('outputs', 'bike_model.pkl')\n",
        "joblib.dump(value=model, filename=model_file)\n",
        "\n",
        "# Register the model\n",
        "print('Registering model...')\n",
        "Model.register(workspace=run.experiment.workspace,\n",
        "               model_path = model_file,\n",
        "               model_name = 'bike_model',\n",
        "               tags={'Training context':'Pipeline'},\n",
        "               properties={'MSE': np.float(msle)})\n",
        "\n",
        "run.complete()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "gather": {
          "logged": 1660593164548
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing cluster! Using it for this session.\n"
          ]
        }
      ],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "cluster_name = 'madison'\n",
        "\n",
        "try: \n",
        "    #Checks if a compute target is already existing\n",
        "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster! Using it for this session.')\n",
        "except ComputeTargetException:\n",
        "    # If compute target not existing, creating new one\n",
        "    try:\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_A2_v2', max_nodes=2)\n",
        "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "        pipeline_cluster.wait_for_completion(show_output=True)\n",
        "    except Exception as ex:\n",
        "        print(ex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting bike_pipeline/experiment_env.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile $experiment_folder/experiment_env.yml\n",
        "name: experiment_env\n",
        "dependencies:\n",
        "- python=3.7.2\n",
        "- pip:\n",
        "  - azureml-defaults\n",
        "  - scikit-learn\n",
        "  - pip\n",
        "  - pyarrow\n",
        "  - hyperopt \n",
        "  - ipykernel\n",
        "  - matplotlib\n",
        "  - pandas\n",
        "  - xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "gather": {
          "logged": 1660592867364
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running config created\n"
          ]
        }
      ],
      "source": [
        "# Create enviroment from .yml file\n",
        "experiment_env = Environment.from_conda_specification('experiment_env', experiment_folder + '/experiment_env.yml')\n",
        "\n",
        "# Register the enviroment \n",
        "experiment_env.register(workspace=ws)\n",
        "registered_env = Environment.get(ws, 'experiment_env')\n",
        "\n",
        "# Create a new runconfig onject for the pipeline\n",
        "pipeline_run_config = RunConfiguration()\n",
        "\n",
        "# Use the compute created above\n",
        "pipeline_run_config.target = pipeline_cluster\n",
        "\n",
        "# Assign the enviroment to the run config\n",
        "pipeline_run_config.environment = registered_env\n",
        "\n",
        "print('Running config created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "gather": {
          "logged": 1660592868598
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipeline steps defined\n"
          ]
        }
      ],
      "source": [
        "# Get the training dataset\n",
        "bike_ds = ws.datasets.get('london_bike_data')\n",
        "\n",
        "# Create an OutputFileDatasetConfig (temp data reference) for data passed from step 1 to step 2\n",
        "prepped_data = OutputFileDatasetConfig('prepped_data')\n",
        "\n",
        "# Step 1, Run the data prep script\n",
        "prep_step = PythonScriptStep(\n",
        "    name='Prepare data',\n",
        "    source_directory=experiment_folder,\n",
        "    script_name='prep_bike.py',\n",
        "    arguments=[\n",
        "        '--input-data', bike_ds.as_named_input('raw_data'),\n",
        "        '--prepped-data', prepped_data],\n",
        "    runconfig=pipeline_run_config,\n",
        "    allow_reuse=True\n",
        ")\n",
        "\n",
        "# Step 2, run the training script\n",
        "train_step = PythonScriptStep(\n",
        "    name='Train and register model',\n",
        "    source_directory=experiment_folder,\n",
        "    script_name='train_bike.py',\n",
        "    arguments=['--training-data', prepped_data.as_input()],\n",
        "    compute_target=pipeline_cluster,\n",
        "    runconfig=pipeline_run_config,\n",
        "    allow_reuse=True\n",
        ")\n",
        "\n",
        "print('Pipeline steps defined')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "gather": {
          "logged": 1660596366556
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipeline is built!\n",
            "Created step Prepare data [9378776c][9f91cb71-c259-480b-b468-9e95c73fbe12], (This step will run and generate new outputs)\n",
            "Created step Train and register model [90fd1d46][4df32f26-873e-4acd-a84d-5cdaf4f4c062], (This step will run and generate new outputs)\n",
            "Submitted PipelineRun ca78698d-8369-4c86-bddd-c5003de18695\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/ca78698d-8369-4c86-bddd-c5003de18695?wsid=/subscriptions/5a361d37-b562-4eee-981b-0936493063e9/resourcegroups/ml_group/workspaces/ml_enviroment&tid=08548f02-0216-4325-938b-fd30f6829e55\n",
            "Pipeline submitted for execution.\n",
            "PipelineRunId: ca78698d-8369-4c86-bddd-c5003de18695\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/ca78698d-8369-4c86-bddd-c5003de18695?wsid=/subscriptions/5a361d37-b562-4eee-981b-0936493063e9/resourcegroups/ml_group/workspaces/ml_enviroment&tid=08548f02-0216-4325-938b-fd30f6829e55\n",
            "PipelineRun Status: Running\n",
            "\n",
            "\n",
            "StepRunId: 3c9dcbd6-855b-4ece-bada-1338d9bac4e6\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/3c9dcbd6-855b-4ece-bada-1338d9bac4e6?wsid=/subscriptions/5a361d37-b562-4eee-981b-0936493063e9/resourcegroups/ml_group/workspaces/ml_enviroment&tid=08548f02-0216-4325-938b-fd30f6829e55\n",
            "StepRun( Prepare data ) Status: Running\n",
            "\n",
            "Streaming azureml-logs/20_image_build_log.txt\n",
            "=============================================\n",
            "2022/09/01 16:54:41 Downloading source code...\n",
            "2022/09/01 16:54:43 Finished downloading source code\n",
            "2022/09/01 16:54:43 Creating Docker network: acb_default_network, driver: 'bridge'\n",
            "2022/09/01 16:54:44 Successfully set up Docker network: acb_default_network\n",
            "2022/09/01 16:54:44 Setting up Docker configuration...\n",
            "2022/09/01 16:54:44 Successfully set up Docker configuration\n",
            "2022/09/01 16:54:44 Logging in to registry: 5e386ef3987f423daf3647923f5ac3a8.azurecr.io\n",
            "2022/09/01 16:54:45 Successfully logged into 5e386ef3987f423daf3647923f5ac3a8.azurecr.io\n",
            "2022/09/01 16:54:45 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
            "2022/09/01 16:54:45 Scanning for dependencies...\n",
            "2022/09/01 16:54:45 Successfully scanned dependencies\n",
            "2022/09/01 16:54:45 Launching container with name: acb_step_0\n",
            "Sending build context to Docker daemon  66.56kB\n",
            "\n",
            "Step 1/21 : FROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220708.v1@sha256:2a7a3804e0b071870e78304aa13dab15c2ece3120f781a99d52f24ff6b71dea6\n",
            "mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220708.v1@sha256:2a7a3804e0b071870e78304aa13dab15c2ece3120f781a99d52f24ff6b71dea6: Pulling from azureml/openmpi4.1.0-ubuntu20.04\n",
            "d7bfe07ed847: Pulling fs layer\n",
            "1a9a51b4af0d: Pulling fs layer\n",
            "9d74d44c539e: Pulling fs layer\n",
            "829bf1798a9e: Pulling fs layer\n",
            "5fe57cb5a06b: Pulling fs layer\n",
            "0b73c9d3e4c7: Pulling fs layer\n",
            "df3a1ae83fc1: Pulling fs layer\n",
            "622a938b5eec: Pulling fs layer\n",
            "9d0e20c4f643: Pulling fs layer\n",
            "e63d29d12ed0: Pulling fs layer\n",
            "5fe57cb5a06b: Waiting\n",
            "0b73c9d3e4c7: Waiting\n",
            "df3a1ae83fc1: Waiting\n",
            "622a938b5eec: Waiting\n",
            "9d0e20c4f643: Waiting\n",
            "e63d29d12ed0: Waiting\n",
            "829bf1798a9e: Waiting\n",
            "d7bfe07ed847: Verifying Checksum\n",
            "d7bfe07ed847: Download complete\n",
            "9d74d44c539e: Verifying Checksum\n",
            "9d74d44c539e: Download complete\n",
            "829bf1798a9e: Verifying Checksum\n",
            "829bf1798a9e: Download complete\n",
            "5fe57cb5a06b: Verifying Checksum\n",
            "5fe57cb5a06b: Download complete\n",
            "df3a1ae83fc1: Verifying Checksum\n",
            "df3a1ae83fc1: Download complete\n",
            "622a938b5eec: Verifying Checksum\n",
            "622a938b5eec: Download complete\n",
            "0b73c9d3e4c7: Download complete\n",
            "e63d29d12ed0: Verifying Checksum\n",
            "e63d29d12ed0: Download complete\n",
            "9d0e20c4f643: Verifying Checksum\n",
            "9d0e20c4f643: Download complete\n",
            "1a9a51b4af0d: Verifying Checksum\n",
            "1a9a51b4af0d: Download complete\n",
            "d7bfe07ed847: Pull complete\n",
            "1a9a51b4af0d: Pull complete\n",
            "9d74d44c539e: Pull complete\n",
            "829bf1798a9e: Pull complete\n",
            "5fe57cb5a06b: Pull complete\n",
            "0b73c9d3e4c7: Pull complete\n",
            "df3a1ae83fc1: Pull complete\n",
            "622a938b5eec: Pull complete\n",
            "9d0e20c4f643: Pull complete\n",
            "e63d29d12ed0: Pull complete\n",
            "Digest: sha256:2a7a3804e0b071870e78304aa13dab15c2ece3120f781a99d52f24ff6b71dea6\n",
            "Status: Downloaded newer image for mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220708.v1@sha256:2a7a3804e0b071870e78304aa13dab15c2ece3120f781a99d52f24ff6b71dea6\n",
            " ---> a126cf3d80b0\n",
            "Step 2/21 : USER root\n",
            " ---> Running in 6dbfe5d4218d\n",
            "Removing intermediate container 6dbfe5d4218d\n",
            " ---> bd7238bbac07\n",
            "Step 3/21 : RUN mkdir -p $HOME/.cache\n",
            " ---> Running in 10e04724cca4\n",
            "Removing intermediate container 10e04724cca4\n",
            " ---> 9f4eb62919e3\n",
            "Step 4/21 : WORKDIR /\n",
            " ---> Running in 29b2eee76120\n",
            "Removing intermediate container 29b2eee76120\n",
            " ---> e049d70018ce\n",
            "Step 5/21 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
            " ---> 8edb95682952\n",
            "Step 6/21 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
            " ---> Running in c3930165dd1e\n",
            "Removing intermediate container c3930165dd1e\n",
            " ---> f9e89edc3405\n",
            "Step 7/21 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
            " ---> 720dcaf31d58\n",
            "Step 8/21 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_29b528f7af499500cf7aa36d33a28977 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
            " ---> Running in 8eb31beec7d6\n",
            "Collecting package metadata (repodata.json): ...working... done\n",
            "Solving environment: ...working... failed\n",
            "\u001b[91m\n",
            "ResolvePackageNotFound: \n",
            "  - hyperopt\n",
            "\n",
            "\u001b[0mThe command '/bin/sh -c ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_29b528f7af499500cf7aa36d33a28977 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig' returned a non-zero code: 1\n",
            "2022/09/01 16:55:16 Container failed during run: acb_step_0. No retries remaining.\n",
            "failed to run step ID: acb_step_0: exit status 1\n",
            "\n",
            "Run ID: cg6 failed after 36s. Error: failed during run, err: exit status 1\n"
          ]
        },
        {
          "ename": "ExperimentExecutionException",
          "evalue": "ExperimentExecutionException:\n\tMessage: The output streaming for the run interrupted.\nBut the run is still executing on the compute target. \nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"The output streaming for the run interrupted.\\nBut the run is still executing on the compute target. \\nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run\"\n    }\n}",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azureml\\azureml-env\\lib\\site-packages\\azureml\\pipeline\\core\\run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[1;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[0;32m    738\u001b[0m                 return self._stream_run_output(timeout_seconds=timeout_seconds,\n\u001b[1;32m--> 739\u001b[1;33m                                                raise_on_error=raise_on_error)\n\u001b[0m\u001b[0;32m    740\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azureml\\azureml-env\\lib\\site-packages\\azureml\\pipeline\\core\\run.py\u001b[0m in \u001b[0;36m_stream_run_output\u001b[1;34m(self, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m             \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azureml\\azureml-env\\lib\\site-packages\\azureml\\pipeline\\core\\run.py\u001b[0m in \u001b[0;36mget_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    654\u001b[0m         \"\"\"\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step_run_provider\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pipeline_run_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_node_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azureml\\azureml-env\\lib\\site-packages\\azureml\\pipeline\\core\\_aeva_provider.py\u001b[0m in \u001b[0;36mget_status\u001b[1;34m(self, pipeline_run_id, node_id)\u001b[0m\n\u001b[0;32m   1219\u001b[0m         \"\"\"\n\u001b[1;32m-> 1220\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_service_caller\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_node_status_code_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline_run_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azureml\\azureml-env\\lib\\site-packages\\azureml\\pipeline\\core\\_restclients\\aeva\\service_caller.py\u001b[0m in \u001b[0;36mget_node_status_code_async\u001b[1;34m(self, pipeline_run_id, node_id)\u001b[0m\n\u001b[0;32m    256\u001b[0m             \u001b[0mworkspace_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workspace_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpipeline_run_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpipeline_run_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_id_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m             custom_headers=self._get_custom_headers())\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azureml\\azureml-env\\lib\\site-packages\\azureml\\pipeline\\core\\_restclients\\aeva\\aml_pipelines_api10.py\u001b[0m in \u001b[0;36mapi_v10_subscriptions_by_subscription_id_resource_groups_by_resource_group_name_providers_microsoft_machine_learning_services_workspaces_by_workspace_name_pipeline_runs_by_pipeline_run_id_graph_node_status_code_post\u001b[1;34m(self, subscription_id, resource_group_name, workspace_name, pipeline_run_id, node_id_path, custom_headers, raw, **operation_config)\u001b[0m\n\u001b[0;32m   2576\u001b[0m         response = self._client.send(\n\u001b[1;32m-> 2577\u001b[1;33m             request, header_parameters, body_content, stream=False, **operation_config)\n\u001b[0m\u001b[0;32m   2578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azureml\\azureml-env\\lib\\site-packages\\msrest\\service_client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, headers, content, **kwargs)\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m             \u001b[0mpipeline_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m             \u001b[1;31m# There is too much thing that expects this method to return a \"requests.Response\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azureml\\azureml-env\\lib\\site-packages\\msrest\\pipeline\\__init__.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[0mfirst_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_impl_policies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_impl_policies\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sender\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfirst_node\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline_request\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azureml\\azureml-env\\lib\\site-packages\\msrest\\pipeline\\__init__.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azureml\\azureml-env\\lib\\site-packages\\msrest\\pipeline\\requests.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azureml\\azureml-env\\lib\\site-packages\\msrest\\pipeline\\__init__.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azureml\\azureml-env\\lib\\site-packages\\msrest\\pipeline\\requests.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    192\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhttp_request\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m         )\n",
            "\u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azureml\\azureml-env\\lib\\site-packages\\msrest\\universal_http\\requests.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[0mrequests_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_configure_send\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRequestsHTTPSender\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mrequests_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azureml\\azureml-env\\lib\\site-packages\\msrest\\universal_http\\requests.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m                 **kwargs)\n\u001b[0m\u001b[0;32m    143\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRequestException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azureml\\azureml-env\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 587\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azureml\\azureml-env\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azureml\\azureml-env\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    498\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    500\u001b[0m                 )\n",
            "\u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azureml\\azureml-env\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    709\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m                 \u001b[0mchunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m             )\n",
            "\u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azureml\\azureml-env\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azureml\\azureml-env\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sock\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azureml\\azureml-env\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[1;31m# Add certificate verification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azureml\\azureml-env\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    174\u001b[0m             conn = connection.create_connection(\n\u001b[1;32m--> 175\u001b[1;33m                 \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m             )\n",
            "\u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azureml\\azureml-env\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mExperimentExecutionException\u001b[0m              Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15732\\1996582810.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#RunDetails(pipeline_run).show()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mpipeline_run\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azureml\\azureml-env\\lib\\site-packages\\azureml\\pipeline\\core\\run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[1;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[0;32m    294\u001b[0m                             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m                                 step_run.wait_for_completion(timeout_seconds=timeout_seconds - time_elapsed,\n\u001b[1;32m--> 296\u001b[1;33m                                                              raise_on_error=raise_on_error)\n\u001b[0m\u001b[0;32m    297\u001b[0m                             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m                                 \u001b[1;31m# If there are package conflicts in the user's environment, the run rehydration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azureml\\azureml-env\\lib\\site-packages\\azureml\\pipeline\\core\\run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[1;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[0;32m    744\u001b[0m                                 \u001b[1;34m\"https://aka.ms/aml-docs-cancel-run\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 746\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mExperimentExecutionException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    747\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m             \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mExperimentExecutionException\u001b[0m: ExperimentExecutionException:\n\tMessage: The output streaming for the run interrupted.\nBut the run is still executing on the compute target. \nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"The output streaming for the run interrupted.\\nBut the run is still executing on the compute target. \\nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run\"\n    }\n}"
          ]
        }
      ],
      "source": [
        "# Construct the pipeline\n",
        "pipeline_steps = [prep_step, train_step]\n",
        "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\n",
        "print('Pipeline is built!')\n",
        "\n",
        "# Create an experiment\n",
        "experiment = Experiment(workspace=ws, name='bike_pipeline')\n",
        "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
        "print('Pipeline submitted for execution.')\n",
        "\n",
        "#RunDetails(pipeline_run).show()\n",
        "pipeline_run.wait_for_completion(show_output=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1660592787429
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train and register model :\n",
            "Prepare data :\n",
            "\t raw_rows : 10886\n",
            "\t processed_rows : 10886\n"
          ]
        }
      ],
      "source": [
        "# Examine metrics recorded by child runs\n",
        "for run in pipeline_run.get_children():\n",
        "    print(run.name, ':')\n",
        "    metrics = run.get_metrics()\n",
        "    for metric_name in metrics:\n",
        "        print('\\t', metric_name, ':', metrics[metric_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bike_model version 6\n",
            "\t Training context : Pipeline\n",
            "\t MSE : 21783.041721689464\n",
            "\n",
            "\n",
            "bike_model version 5\n",
            "\t Training context : Pipeline\n",
            "\t MSE : 774685.1528476852\n",
            "\n",
            "\n",
            "bike_model version 4\n",
            "\t Training context : Pipeline\n",
            "\t MSE : 0.012539497713253425\n",
            "\n",
            "\n",
            "windpred_automl_lightgbm version 1\n",
            "\t azureml.datastoreId : /subscriptions/5a361d37-b562-4eee-981b-0936493063e9/resourceGroups/ml_group/providers/Microsoft.MachineLearningServices/workspaces/ml_enviroment/datastores/workspaceartifactstore\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Register a new model with a training context tag to indicate it was trained in a pipeline\n",
        "for model in Model.list(ws):\n",
        "    print(model.name, 'version', model.version)\n",
        "    for tag_name in model.tags:\n",
        "        tag = model.tags[tag_name]\n",
        "        print('\\t', tag_name, ':', tag)\n",
        "    for prop_name in model.properties:\n",
        "        prop = model.properties[prop_name]\n",
        "        print('\\t', prop_name, ':', prop)\n",
        "    print('\\n')"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.7.0 ('azureml-env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "d2ef8cebf12da122307cb1f3dbb3292484f04da033a29bc74331676dd444be10"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
